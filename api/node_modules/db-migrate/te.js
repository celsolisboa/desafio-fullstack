exports.migrate = async (db, opt) => {
  const { util } = opt.dbm;

  await db.insert(
    'test',
    // can recieve object or array of same structured objs
    util.insertObj([
      { column1: '1', column2: '2' },
      { column1: '1', column2: '3' },
      { column1: '2', column2: '4' }
    ])
  );
  /**
   * For efficiency insertObj shouldn't be used on big operations
   * The previous command essentially expands to:
   */
  await db.insert('test', {
    columns: ['column1', 'column2'],
    data: ['1', '2', '1', '3', '2', '4']
  });

  /**
   * The streaming interface can be accessed by passing a config object
   * with the predefinition of the incoming data and the stream to consume
   * from.
   */
  const streamConfig = {
    columns: ['column1', 'column2'],
    stream: myDataStream
  };
  await db.insert.stream('test', streamConfig);

  /**
   * Streaming can be used with helper functions such as structured readers.
   */
  await db.insert.stream(
    'test',
    util.readStructured('./data.csv', { delimiter: ';' })
  );

  /**
   * And of course also read from other tables data.
   */
  await db.insert.from('test', 'readme', {
    map: {
      source1: 'column1',
      source2: 'column2'
    },
    search: 'ventilation NOT NULL'
  });

  /**
   * Instead of search as a short hand, the get property
   * will give access to get directly.
   */
  await db.insert.from('test', 'readme', {
    map: {
      source1: 'column1',
      source2: 'column2'
    },
    get: {
      /* ... */
    }
  });
};

exports._meta = {
  version: 2,
  DML: true
};
